{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1...\n",
      "Processing chunk 2...\n",
      "Processing chunk 3...\n",
      "Processing chunk 4...\n",
      "Processing chunk 5...\n",
      "Processing chunk 6...\n",
      "Processing chunk 7...\n",
      "Processing chunk 8...\n",
      "Processing chunk 9...\n",
      "Processing chunk 10...\n",
      "Processing chunk 11...\n",
      "Processing chunk 12...\n",
      "Processing chunk 13...\n",
      "Processing chunk 14...\n",
      "Processing chunk 15...\n",
      "Processing chunk 16...\n",
      "Processing chunk 17...\n",
      "Processing chunk 18...\n",
      "Processing chunk 19...\n",
      "Processing chunk 20...\n",
      "MSE RandomForestRegressor: 0.03793298025989009\n",
      "Score RandomForestRegressor: 0.9619387740622833\n",
      "MSE DecisionTreeRegressor: 0.07358058433253363\n",
      "Score DecisionTreeRegressor: 0.9261706508235772\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "chunk_size = 50000\n",
    "\n",
    "# Initialize models\n",
    "model = {\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "}\n",
    "\n",
    "# Storage for training data\n",
    "all_X_train = []\n",
    "all_y_train = []\n",
    "total_X_test = pd.DataFrame()\n",
    "total_y_test = pd.DataFrame()\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for df in pd.read_csv(\"training_dataset.csv\", chunksize=chunk_size):\n",
    "    if counter == 20:\n",
    "        break\n",
    "    counter += 1\n",
    "    print(f\"Processing chunk {counter}...\")\n",
    "\n",
    "    # Handle missing values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Rename columns\n",
    "    column_names = [\"ID\", \"vendorid\",\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\",\"passenger_count\", \"trip_distance\",\n",
    "                    \"ratecodeid\",\"store_and_fwd_flag\",\"pulocationid\",\"dolocationid\",\"payment_type\",\"fare_amount\",\n",
    "                    \"extra\",\"mta_tax\",\"tip_amount\",\"tolls_amount\",\"improvement_surcharge\",\"total_amount\",\n",
    "                    \"congestion_surcharge\",\"airport_fee\",\"duration\"]                  \n",
    "    df.columns = column_names\n",
    "    df.drop(columns=[\"ID\"], inplace=True)\n",
    "\n",
    "    # Convert datetime columns\n",
    "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "\n",
    "    df['tpep_pickup_hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "    df['tpep_dropoff_hour'] = df['tpep_dropoff_datetime'].dt.hour\n",
    "\n",
    "    df.drop(columns=['tpep_pickup_datetime', 'tpep_dropoff_datetime'], inplace=True)\n",
    "\n",
    "    # Convert categorical values\n",
    "    df['store_and_fwd_flag'] = df['store_and_fwd_flag'].map({'N': 0, 'Y': 1})\n",
    "\n",
    "    # Outlier filtering\n",
    "    df = df[(df['duration'] < 2880) & (df['duration'] > 30)]\n",
    "    df = df[(df['trip_distance'] < 300) & (df['trip_distance'] > 0.25)]\n",
    "\n",
    "    # Drop unneeded columns\n",
    "    df.drop(columns=[\n",
    "        'tpep_dropoff_hour', 'airport_fee', 'payment_type', 'congestion_surcharge',\n",
    "        'passenger_count', 'vendorid', 'improvement_surcharge', 'tolls_amount',\n",
    "        'extra', 'tip_amount'\n",
    "    ], inplace=True)\n",
    "\n",
    "    # Split features and target\n",
    "    X_data = df.drop(columns=['duration'])\n",
    "    y_data = df['duration']\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Accumulate training data\n",
    "    all_X_train.append(X_train)\n",
    "    all_y_train.append(y_train)\n",
    "\n",
    "    # Accumulate test data\n",
    "    total_X_test = pd.concat([total_X_test, X_test])\n",
    "    total_y_test = pd.concat([total_y_test, y_test])\n",
    "\n",
    "# Combine all training data\n",
    "final_X_train = pd.concat(all_X_train)\n",
    "final_y_train = pd.concat(all_y_train)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "final_X_train = pd.DataFrame(scaler.fit_transform(final_X_train), columns=final_X_train.columns)\n",
    "total_X_test = pd.DataFrame(scaler.transform(total_X_test), columns=total_X_test.columns)\n",
    "\n",
    "# Standardize the target variable\n",
    "scaler_y = StandardScaler()\n",
    "final_y_train = scaler_y.fit_transform(final_y_train.values.reshape(-1, 1)).flatten()\n",
    "total_y_test = scaler_y.transform(total_y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Train models only once\n",
    "reg = {}\n",
    "for model_name in model.keys():\n",
    "    \n",
    "    reg[model_name] = model[model_name].fit(final_X_train, final_y_train)\n",
    "\n",
    "# Evaluate models\n",
    "for model_name in model.keys():\n",
    "    y_pred = reg[model_name].predict(total_X_test)\n",
    "    mse = mean_squared_error(y_true=total_y_test, y_pred=y_pred)\n",
    "    \n",
    "    score = r2_score(y_true=total_y_test, y_pred=y_pred)\n",
    "\n",
    "    print(f\"MSE {model_name}: {mse}\")\n",
    "    print(f\"Score {model_name}: {score}\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
