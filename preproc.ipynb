{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype as is_num\n",
    "from river import tree\n",
    "\n",
    "chunk_size = 50000\n",
    "\n",
    "# Storage for training data\n",
    "all_X_train = []\n",
    "all_y_train = []\n",
    "total_X_test = pd.DataFrame()\n",
    "total_y_test = pd.Series(dtype='float64')\n",
    "\n",
    "# Columns\n",
    "all_columns = ['ID', 'vendorid', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
    "       'passenger_count', 'trip_distance', 'ratecodeid', 'store_and_fwd_flag',\n",
    "       'pulocationid', 'dolocationid', 'payment_type', 'fare_amount', 'extra',\n",
    "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
    "       'total_amount', 'congestion_surcharge', 'airport_fee', 'duration']\n",
    "\n",
    "columns_in_eval = ['ID', 'vendorid', 'tpep_pickup_datetime', 'passenger_count',\n",
    "       'trip_distance', 'ratecodeid', 'store_and_fwd_flag', 'pulocationid',\n",
    "       'dolocationid', 'payment_type', 'fare_amount', 'extra', 'mta_tax',\n",
    "       'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount',\n",
    "       'congestion_surcharge', 'airport_fee']\n",
    "\n",
    "columns_not_in_eval = list(set(all_columns) - set(columns_in_eval))\n",
    "\n",
    "unneeded_columns = [ \n",
    "        'airport_fee', 'payment_type', 'congestion_surcharge',\n",
    "        'passenger_count', 'vendorid', 'improvement_surcharge', 'tolls_amount',\n",
    "        'extra', 'tip_amount', 'ratecodeid', 'store_and_fwd_flag',\n",
    "    ]\n",
    "\n",
    "needed_columns = list(set(all_columns) - set(unneeded_columns))\n",
    "\n",
    "# Read data in chunks\n",
    "chunks = pd.read_csv(\"training_dataset.csv\", chunksize=chunk_size, usecols=needed_columns)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, warm_start=True),\n",
    "    \"SGDRegressor\": SGDRegressor(alpha=0.0001, eta0=0.0001, learning_rate=\"adaptive\", warm_start=True),\n",
    "    \"HoeffdingTreeRegressor\": tree.HoeffdingTreeRegressor(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 0...\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for df in chunks:\n",
    "    if counter == 1:\n",
    "        break\n",
    "    print(f\"Processing chunk {counter}...\")\n",
    "    counter += 1\n",
    "    \n",
    "    # Drop ID column\n",
    "    df.drop(columns=['ID'], inplace=True)\n",
    "    \n",
    "    # Handle missing values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Convert datetime columns\n",
    "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    df['tpep_pickup_hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "    df.drop(columns=['tpep_pickup_datetime'], inplace=True)\n",
    "    df.drop(columns=['tpep_dropoff_datetime'], inplace=True)\n",
    "\n",
    "    \n",
    "    for col in df.columns:\n",
    "        assert is_num(df[col]), f\"The '{col}' column contained categorical values\"\n",
    "    \n",
    "    \n",
    "    # # Outlier filtering\n",
    "    # df = df[(df['duration'] < 2880) & (df['duration'] > 30)]\n",
    "    # df = df[(df['trip_distance'] < 300) & (df['trip_distance'] > 0.25)]\n",
    "    # df = df[(df['fare_amount'] < 300) & (df['fare_amount'] > 0)]\n",
    "    # # df = df.applymap(lambda x: x if x > 0 else None).dropna()\n",
    "    df = df[df.ge(0.01).all(1)]\n",
    "\n",
    "\n",
    "    for col in df.columns:\n",
    "        assert (df[col] > 0).all(), f\"The '{col}' column contained negative values\"\n",
    "\n",
    "\n",
    "    # Split features and target\n",
    "    X_data = df.drop(columns = 'duration')\n",
    "    y_data = df['duration']\n",
    "\n",
    "\n",
    "    # Train-tt\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize features\n",
    "    #X_scaler = RobustScaler(quantile_range=(1.0, 99.0))\n",
    "    X_scaler = StandardScaler()\n",
    "    X_train = pd.DataFrame(X_scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "    X_test = pd.DataFrame(X_scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "    #y_Scaler = RobustScaler(quantile_range=(1.0, 99.0))\n",
    "    y_Scaler = StandardScaler()\n",
    "    y_train = y_Scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "    y_test = pd.Series(y_Scaler.transform(y_test.values.reshape(-1, 1)).flatten(), index=X_test.index)\n",
    "\n",
    "    # Accumulate test data\n",
    "    total_X_test = pd.concat([total_X_test, X_test])\n",
    "    total_y_test = pd.concat([total_y_test, y_test])\n",
    "    \n",
    "    # Train the model chunk by chunk    \n",
    "    for model_name in models.keys():\n",
    "            if model_name == \"RandomForestRegressor\":\n",
    "                if counter == 0:\n",
    "                    models[model_name].fit(X_train, y_train)  # First chunk: normal fit\n",
    "                else:\n",
    "                    models[model_name].n_estimators += 10  # Increase trees\n",
    "                    models[model_name].fit(X_train, y_train)  # Fit on new chunk\n",
    "            elif model_name == \"SGDRegressor\":\n",
    "                models[model_name].partial_fit(X_train, y_train)\n",
    "            elif model_name == \"HoeffdingTreeRegressor\":\n",
    "               for x, y in zip(X_train.to_dict(orient=\"records\"), y_train):\n",
    "                    models[model_name].learn_one(x, y)\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE RandomForestRegressor: 1.0389\n",
      "Score RandomForestRegressor: -0.0122\n",
      "MSE SGDRegressor: 364020596224376.8125\n",
      "Score SGDRegressor: -354648821548328.5625\n",
      "MSE HoeffdingTreeRegressor: 153096.6067\n",
      "Score HoeffdingTreeRegressor: -149154.1074\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "for model_name in models.keys():\n",
    "    if model_name == \"SGDRegressor\":\n",
    "        # Predict & inverse transform\n",
    "        y_pred = models[\"SGDRegressor\"].predict(total_X_test)\n",
    "        y_pred = y_Scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "\n",
    "        # Compute MSE & R2 score\n",
    "        mse = mean_squared_error(y_true=total_y_test, y_pred=y_pred)\n",
    "        score = r2_score(y_true=total_y_test, y_pred=y_pred)\n",
    "\n",
    "    elif model_name == \"HoeffdingTreeRegressor\":\n",
    "        # Predict using predict_one()\n",
    "        y_pred = [models[\"HoeffdingTreeRegressor\"].predict_one(x) for x in total_X_test.to_dict(orient=\"records\")]\n",
    "\n",
    "        # Compute MSE & R2 score\n",
    "        mse = mean_squared_error(y_true=total_y_test, y_pred=y_pred)\n",
    "        score = r2_score(y_true=total_y_test, y_pred=y_pred)\n",
    "\n",
    "    else:  # RandomForestRegressor or other batch models\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        total_X_test = pd.DataFrame(X_scaler.transform(total_X_test), columns=total_X_test.columns, index=total_X_test.index)\n",
    "        y_pred = models[model_name].predict(total_X_test)\n",
    "\n",
    "        # Compute MSE & R2 score\n",
    "        mse = mean_squared_error(y_true=total_y_test, y_pred=y_pred)\n",
    "        score = r2_score(y_true=total_y_test, y_pred=y_pred)\n",
    "        \n",
    "\n",
    "    print(f\"MSE {model_name}: {mse:.4f}\")\n",
    "    print(f\"Score {model_name}: {score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df_eval = pd.read_csv(\"eval.csv\")\n",
    "\n",
    "# Store IDs for final output\n",
    "eval_ids = df_eval[\"ID\"]\n",
    "\n",
    "# Drop ID column\n",
    "df_eval.drop(columns=[\"ID\"], inplace=True)\n",
    "\n",
    "# Convert datetime column\n",
    "df_eval['tpep_pickup_datetime'] = pd.to_datetime(df_eval['tpep_pickup_datetime'])\n",
    "df_eval['tpep_pickup_hour'] = df_eval['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "cols_to_drop = unneeded_columns + ['tpep_pickup_datetime']\n",
    "# Drop only existing columns\n",
    "df_eval.drop(columns=[col for col in cols_to_drop if col in df_eval.columns], inplace=True)\n",
    "\n",
    "# Standardize features\n",
    "#X_scaler = RobustScaler(quantile_range=(1.0, 99.0))\n",
    "eval_scaler = StandardScaler()\n",
    "df_eval = pd.DataFrame(eval_scaler.fit_transform(df_eval), columns=df_eval.columns, index=df_eval.index)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_eval = models[\"RandomForestRegressor\"].predict(df_eval)\n",
    "\n",
    "# Save output\n",
    "df_out = pd.DataFrame({\"ID\": eval_ids, \"duration\": y_pred_eval}).set_index(\"ID\")\n",
    "df_out.to_csv(\"submission.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
